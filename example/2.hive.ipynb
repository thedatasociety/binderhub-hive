{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Initial definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HADOOP_VERSION=2.9.2\n",
      "env: HADOOP_PATH=hadoop-2.9.2\n"
     ]
    }
   ],
   "source": [
    "%env HADOOP_VERSION     2.9.2\n",
    "%env HADOOP_PATH hadoop-2.9.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Downloading Hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: wget: not found\n"
     ]
    }
   ],
   "source": [
    "!wget http://ftp.unicamp.br/pub/apache/hadoop/common/hadoop-${HADOOP_VERSION}/hadoop-${HADOOP_VERSION}.tar.gz -q --show-progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Extracting compressed files and removing .tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: tar: not found\n",
      "/bin/sh: 1: rm: not found\n"
     ]
    }
   ],
   "source": [
    "# !rm ${HADOOP_PATH} -r\n",
    "!tar -xvf hadoop-${HADOOP_VERSION}.tar.gz >/dev/null \n",
    "!rm       hadoop-${HADOOP_VERSION}.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "## Discovering the Java path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: which: not found\n",
      "/bin/sh: 1: readlink: not found\n",
      "/bin/sh: 1: dirname: not found\n",
      "/bin/sh: 1: dirname: not found\n"
     ]
    }
   ],
   "source": [
    "!dirname $(dirname $(readlink -f $(which javac)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Java path envvar\n",
    "\n",
    "We also added it to user's .bashrc so it will be loaded as the nodes perform ssh connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\n"
     ]
    }
   ],
   "source": [
    "%env JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.bashrc\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.profile\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ${HADOOP_PATH}/etc/hadoop/hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Hadoop in Standalone Mode (local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce in the local filesystem - word count example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hadoop jar ${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount \\\n",
    "                               ./resources/examples/newyorknewyork.txt ./output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ls: not found\n"
     ]
    }
   ],
   "source": [
    "!ls ./output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cat: not found\n"
     ]
    }
   ],
   "source": [
    "! cat ./output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Hadoop in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting sshd server\n",
    "\n",
    "Check `/binder/postBuild` and `/resources/configs/ssh/sshd_config` files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/sbin/sshd -f resources/configs/ssh/sshd_config "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding names to know hosts \n",
    "\n",
    "Commands below stablish ssh connections to used host names/ips. This step avoids yes/no host confirmation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: ssh: not found\n",
      "/bin/sh: 1: ssh: not found\n"
     ]
    }
   ],
   "source": [
    "!ssh -o \"StrictHostKeyChecking no\" $USER@localhost -p 8822 -C \"exit\" \n",
    "!ssh -o \"StrictHostKeyChecking no\" $USER@0.0.0.0   -p 8822 -C \"exit\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding ssh options to Hadoop via envvar\n",
    "\n",
    "* connecting in a diferent port (`-p 8822`)\n",
    "* avoiding host key checking (`-o StrictHostKeyChecking=no`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HADOOP_SSH_OPTS=-o StrictHostKeyChecking=no -p 8822\n"
     ]
    }
   ],
   "source": [
    "%env HADOOP_SSH_OPTS= -o StrictHostKeyChecking=no -p 8822"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PDSH_RCMD_TYPE=ssh\n"
     ]
    }
   ],
   "source": [
    "%env PDSH_RCMD_TYPE ssh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying configurations files to Hadoop folder\n",
    "\n",
    "Check the configuration files accordingly to the Hadoop version. \n",
    "Refer to the `/resources/configs/hadoop/<version>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cp: not found\n",
      "/bin/sh: 1: cp: not found\n"
     ]
    }
   ],
   "source": [
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/core-site.xml   ${HADOOP_PATH}/etc/hadoop/\n",
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/hdfs-site.xml   ${HADOOP_PATH}/etc/hadoop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Formatting the filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs namenode -format -force -nonInteractive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting DFS (NameNode, SecondaryNameNode, and DataNode daemons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n",
      "/bin/sh: 1: jps: not found\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/sbin/start-dfs.sh\n",
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce - Word count example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating folders in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n",
      "/usr/bin/env: ‘bash’: No such file or directory\n",
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/\n",
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/matheus/\n",
    "!${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying a file to a folder in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -put ./resources/examples/newyorknewyork.txt /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in a folder of the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving the contents of a file in the distributed file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/input/newyorknewyork.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Running MapReduce job in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hadoop jar  ./${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount \\\n",
    "                                /user/matheus/input /user/matheus/output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/output/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Starting YARN in Pseudo-Distributed Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## Preparing the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copying configurations files to Hadoop folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: cp: not found\n",
      "/bin/sh: 1: cp: not found\n"
     ]
    }
   ],
   "source": [
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/mapred-site.xml ${HADOOP_PATH}/etc/hadoop/\n",
    "!cp resources/configs/hadoop/${HADOOP_VERSION}/yarn-site.xml   ${HADOOP_PATH}/etc/hadoop/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Starting YARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n",
      "/bin/sh: 1: jps: not found\n"
     ]
    }
   ],
   "source": [
    "!${HADOOP_PATH}/sbin/start-yarn.sh\n",
    "!jps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "## MapReduce via YARN - Word count example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/yarn jar  ./${HADOOP_PATH}/share/hadoop/mapreduce/hadoop-mapreduce-examples-${HADOOP_VERSION}.jar wordcount \\\n",
    "                                /user/matheus/input /user/matheus/output2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Listing files in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -ls /user/matheus/output2/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": true
   },
   "source": [
    "### Reading output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/env: ‘bash’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!./${HADOOP_PATH}/bin/hdfs dfs -cat /user/matheus/output2/part-r-00000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hive Initial definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env HIVE_VERSION     hive-2.3.5\n",
    "%env HIVE_PATH apache-hive-2.3.5-bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Enviroment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Hive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://ftp.unicamp.br/pub/apache/hive/${HIVE_VERSION}/${HIVE_PATH}.tar.gz -q --show-progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting compressed files and removing .tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvf ${HIVE_PATH}.tar.gz >/dev/null \n",
    "!rm       ${HIVE_PATH}.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Hive path envvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64\n",
    "\n",
    "%env HIVE_HOME=/home/jovyan/${HIVE_PATH}\n",
    "%env PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PATH/bin:$HIVE_HOME/bin:$HIVE_HOME/conf\n",
    "!export JAVA_HOME CLASS_PATH PATH HIVE_HOME\n",
    "\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.bashrc\n",
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ~/.profile\n",
    "!echo \"export HIVE_HOME=/home/jovyan/$HIVE_PATH \" >> ~/.bashrc\n",
    "!echo \"export HIVE_HOME=/home/jovyan/$HIVE_PATH \" >> ~/.profile\n",
    "!echo \"export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PATH/bin:$HIVE_HOME/bin:$HIVE_HOME/conf \" >> ~/.bashrc\n",
    "!echo \"export PATH=$PATH:$JAVA_HOME/bin:$HADOOP_PATH/bin:$HIVE_HOME/bin:$HIVE_HOME/conf \" >> ~/.profile\n",
    "!source /etc/profile\n",
    "\n",
    "#!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 \" >> ${HADOOP_PATH}/etc/hadoop/hadoop-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure hive-env.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo \"export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64\" > /home/jovyan/${HIVE_PATH}/bin/hive-env.sh\n",
    "!echo \"export HADOOP_HOME=$HADOOP_PATH\" >> /home/jovyan/${HIVE_PATH}/bin/hive-env.sh\n",
    "!echo \"export HIVE_HOME=/home/jovyan/$HIVE_PATH\" >> /home/jovyan/${HIVE_PATH}/bin/hive-env.sh\n",
    "\n",
    "# Hive Configuration Directory can be controlled by:\n",
    "!echo \"export HIVE_CONF_DIR=$HIVE_HOME/conf\" >> /home/jovyan/${HIVE_PATH}/bin/hive-env.sh\n",
    "\n",
    "# Folder containing extra libraries required for hive compilation/execution can be controlled by:\n",
    "!echo \"export HIVE_AUX_JARS_PATH=$HIVE_HOME/lib/*\" >> /home/jovyan/${HIVE_PATH}/bin/hive-env.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create HDFS directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!./hadoop-2.9.2/bin/hdfs dfs -mkdir /user\n",
    "#!./${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/hive\n",
    "#!./${HADOOP_PATH}/bin/hdfs dfs -mkdir /user/hive/warehouse\n",
    "#!./${HADOOP_PATH}/bin/hdfs dfs -mkdir /tmp/hive\n",
    "#!./${HADOOP_PATH}/bin/hdfs dfs -chmod  777 /user/hive/warehouse\n",
    "#!./${HADOOP_PATH}/bin/hdfs dfs -chmod  777 /tmp/hive\n",
    "!./${HADOOP_PATH}/bin/hdfs dfs -ls /user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create database to store the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!.$HIVE_HOME/bin/schematool –initschema –dbtype derby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
